{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daf71da",
   "metadata": {},
   "source": [
    "# 06 Texte auswerten mit dem Computer\n",
    "\n",
    "Ein wenig rechnen mit Wörtern: Welche Stichwörter beschreiben einen Text am besten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a4cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eine': 4, 'das': 4, 'was': 3, 'ist': 3, 'nächste': 3, 'chatgpt': 2, 'ein': 2, 'die': 2, 'ki': 2, 'sie': 2, 'einer': 2, 'und': 2, 'wieder': 2, 'etc': 1, 'eigentlich': 1, 'benutzeroberfläche': 1, 'unter': 1, 'der': 1, 'sich': 1, 'so': 1, 'genanntes': 1, 'generatives': 1, 'sprachmodell': 1, 'verbirgt': 1, 'eigentliche': 1, 'maschine': 1, 'wohlgeformte': 1, 'texte': 1, 'produzieren': 1, 'kann': 1, 'hat': 1, 'aus': 1, 'enormen': 1, 'menge': 1, 'von': 1, 'menschengemachten': 1, 'texten': 1, 'gelernt': 1, 'wie': 1, 'würden': 1, 'menschen': 1, 'in': 1, 'vergleichbaren': 1, 'situation': 1, 'wohl': 1, 'wort': 1, 'wählen': 1, 'dann': 1, 'nicht': 1, 'wahrheitsmaschine': 1, 'weltgeist': 1, 'oder': 1, 'echte': 1, 'künstliche': 1, 'intelligenz': 1, 'im': 1, 'sinne': 1, 'dessen': 1, 'forscher': 1, 'innen': 1, 'erst': 1, 'noch': 1, 'erreichen': 1, 'wollen': 1, 'keine': 1, 'agi': 1, 'artificial': 1, 'general': 1, 'intelligence': 1}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import re\n",
    "    \n",
    "def bag_of_words(text):\n",
    "    # Convert to lowercase and extract words\n",
    "    \n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    \n",
    "    # Count frequencies and return as dict sorted by frequency\n",
    "    word_counts = Counter(words)\n",
    "    return dict(sorted(word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "text1 = \"\"\"\n",
    "Was chatGPT (etc.) eigentlich ist: eine Benutzeroberfläche, unter der sich ein so \n",
    "genanntes “Generatives Sprachmodell” verbirgt, die eigentliche KI: eine Maschine, \n",
    "die wohlgeformte Texte produzieren kann. Das hat sie aus einer enormen Menge von \n",
    "menschengemachten Texten gelernt: Wie würden Menschen in einer vergleichbaren \n",
    "Situation wohl das nächste Wort wählen? Und dann wieder das nächste, und wieder \n",
    "das nächste.  \n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "Was sie nicht ist: Eine Wahrheitsmaschine, ein Weltgeist oder eine echte \n",
    "“Künstliche Intelligenz” im Sinne dessen, was KI-Forscher:innen erst noch \n",
    "erreichen wollen: chatGPT ist keine  “AGI” (“Artificial General Intelligence”). \n",
    "\"\"\"\n",
    "\n",
    "print(bag_of_words(text1 + text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802fd38",
   "metadata": {},
   "source": [
    "**Jetzt du:** Lass dir ein Programm schreiben, das die Häufigkeit der einzelnen Wörter angibt: Für ```text1```, für ```text2``` - und für beide Texte zusammen. \n",
    "\n",
    "## Topic Modeling: Die richtigen Schlagworte extrahieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bag_of_words(text1))\n",
    "print(bag_of_words(text2))\n",
    "print(bag_of_words(text1 + text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662655e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tf_idf_keywords(text, threshold=4):\n",
    "    # Simple TF-IDF implementation\n",
    " \n",
    "    \n",
    "    # Tokenize and normalize\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    \n",
    "    # Calculate term frequency\n",
    "    tf = Counter(words)\n",
    "    \n",
    "    # Calculate document frequency\n",
    "    df = Counter()\n",
    "    for doc in words:\n",
    "        doc_words = set(re.findall(r'\\w+', doc.lower()))\n",
    "        for word in doc_words:\n",
    "            df[word] += 1\n",
    "    \n",
    "    # Calculate TF-IDF scores\n",
    "    tf_idf = {}\n",
    "    N = len(words)\n",
    "    \n",
    "    for word, frequency in tf.items():\n",
    "        if word in df:\n",
    "            idf = math.log(N / df[word])\n",
    "            val = frequency * idf\n",
    "            if val >= threshold:\n",
    "                tf_idf[word] = val\n",
    "    \n",
    "    # Return sorted keywords by weight\n",
    "    return dict(sorted(tf_idf.items(), key=lambda x: x[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de2aea",
   "metadata": {},
   "source": [
    "**Jetzt du**: Wende die tf_idf Funktion auf text1 und text2 an - und vergleiche mit dem Bag of words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c68cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eine': 4, 'das': 4, 'was': 3, 'ist': 3, 'nächste': 3, 'chatgpt': 2, 'ein': 2, 'die': 2, 'ki': 2, 'sie': 2, 'einer': 2, 'und': 2, 'wieder': 2, 'etc': 1, 'eigentlich': 1, 'benutzeroberfläche': 1, 'unter': 1, 'der': 1, 'sich': 1, 'so': 1, 'genanntes': 1, 'generatives': 1, 'sprachmodell': 1, 'verbirgt': 1, 'eigentliche': 1, 'maschine': 1, 'wohlgeformte': 1, 'texte': 1, 'produzieren': 1, 'kann': 1, 'hat': 1, 'aus': 1, 'enormen': 1, 'menge': 1, 'von': 1, 'menschengemachten': 1, 'texten': 1, 'gelernt': 1, 'wie': 1, 'würden': 1, 'menschen': 1, 'in': 1, 'vergleichbaren': 1, 'situation': 1, 'wohl': 1, 'wort': 1, 'wählen': 1, 'dann': 1, 'nicht': 1, 'wahrheitsmaschine': 1, 'weltgeist': 1, 'oder': 1, 'echte': 1, 'künstliche': 1, 'intelligenz': 1, 'im': 1, 'sinne': 1, 'dessen': 1, 'forscher': 1, 'innen': 1, 'erst': 1, 'noch': 1, 'erreichen': 1, 'wollen': 1, 'keine': 1, 'agi': 1, 'artificial': 1, 'general': 1, 'intelligence': 1}\n",
      "{'eine': 12.409368034448997, 'das': 12.409368034448997, 'was': 10.17007224319209, 'ist': 10.17007224319209, 'nächste': 10.17007224319209, 'chatgpt': 7.590978378344389, 'ein': 7.590978378344389, 'die': 7.590978378344389, 'ki': 7.590978378344389, 'sie': 7.590978378344389, 'einer': 7.590978378344389, 'und': 7.590978378344389, 'wieder': 7.590978378344389, 'etc': 4.48863636973214, 'eigentlich': 4.48863636973214, 'benutzeroberfläche': 4.48863636973214, 'unter': 4.48863636973214, 'der': 4.48863636973214, 'sich': 4.48863636973214, 'so': 4.48863636973214, 'genanntes': 4.48863636973214, 'generatives': 4.48863636973214, 'sprachmodell': 4.48863636973214, 'verbirgt': 4.48863636973214, 'eigentliche': 4.48863636973214, 'maschine': 4.48863636973214, 'wohlgeformte': 4.48863636973214, 'texte': 4.48863636973214, 'produzieren': 4.48863636973214, 'kann': 4.48863636973214, 'hat': 4.48863636973214, 'aus': 4.48863636973214, 'enormen': 4.48863636973214, 'menge': 4.48863636973214, 'von': 4.48863636973214, 'menschengemachten': 4.48863636973214, 'texten': 4.48863636973214, 'gelernt': 4.48863636973214, 'wie': 4.48863636973214, 'würden': 4.48863636973214, 'menschen': 4.48863636973214, 'in': 4.48863636973214, 'vergleichbaren': 4.48863636973214, 'situation': 4.48863636973214, 'wohl': 4.48863636973214, 'wort': 4.48863636973214, 'wählen': 4.48863636973214, 'dann': 4.48863636973214, 'nicht': 4.48863636973214, 'wahrheitsmaschine': 4.48863636973214, 'weltgeist': 4.48863636973214, 'oder': 4.48863636973214, 'echte': 4.48863636973214, 'künstliche': 4.48863636973214, 'intelligenz': 4.48863636973214, 'im': 4.48863636973214, 'sinne': 4.48863636973214, 'dessen': 4.48863636973214, 'forscher': 4.48863636973214, 'innen': 4.48863636973214, 'erst': 4.48863636973214, 'noch': 4.48863636973214, 'erreichen': 4.48863636973214, 'wollen': 4.48863636973214, 'keine': 4.48863636973214, 'agi': 4.48863636973214, 'artificial': 4.48863636973214, 'general': 4.48863636973214, 'intelligence': 4.48863636973214}\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words(text1 + text2))\n",
    "print(tf_idf_keywords(text1 + text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1203d009",
   "metadata": {},
   "source": [
    "Okay... aber zu viel Müll: Wir müssen: \n",
    "- die **Stoppwörter** rausnehmen (ein, die, und...)\n",
    "- die Wortstämme (Lemmata) extrahieren\n",
    "\n",
    "Das machen wir mit einer Spezial-Bibliothek (die auch schon ein wenig KI benutzt): Spacy. \n",
    "\n",
    "Außerdem benutzen wir die Tabellen-Bibliothek pandas - und wir geben ihr einen anderen Namen. Details sind nicht so wichtig; einfach schauen: ähnliche Code-Schnipsel sieht man sehr oft!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5afa7ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (2.3.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (2.12.3)\n",
      "Requirement already satisfied: jinja2 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.2.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.4.1)\n",
      "Requirement already satisfied: wrapt in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (2.0.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from jinja2->spacy) (3.0.3)\n",
      "Requirement already satisfied: scikit.learn in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from scikit.learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from scikit.learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from scikit.learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from scikit.learn) (3.6.0)\n",
      "Requirement already satisfied: pandas in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!pip install scikit.learn\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7e4f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "\n",
      "Was chatGPT (etc.) eigentlich ist: eine Benutzeroberfläche, unter der sich ein so \n",
      "genanntes “Generatives Sprachmodell” verbirgt, die eigentliche KI: eine Maschine, \n",
      "die wohlgeformte Texte produzieren kann. Das hat sie aus einer enormen Menge von \n",
      "menschengemachten Texten gelernt: Wie würden Menschen in einer vergleichbaren \n",
      "Situation wohl das nächste Wort wählen? Und dann wieder das nächste, und wieder \n",
      "das nächste.  \n",
      "\n",
      "Was sie nicht ist: Eine Wahrheitsmaschine, ein Weltgeist oder eine echte \n",
      "“Künstliche Intelligenz” im Sinne dessen, was KI-Forscher:innen erst noch \n",
      "erreichen wollen: chatGPT ist keine  “AGI” (“Artificial General Intelligence”). \n",
      "\n",
      "\n",
      "Lemmatized text:\n",
      "\n",
      " chatGPT etc. eigentlich Benutzeroberfläche \n",
      " genannt Generativ Sprachmodell verbirgen eigentlich KI Maschine \n",
      " wohlgeformt Text produzieren enorm Menge \n",
      " menschengemachten Text lernen Mensch vergleichbar \n",
      " Situation nächster Wort wählen nächster \n",
      " nächster  \n",
      "\n",
      " Wahrheitsmaschine Weltgeist echt \n",
      " Künstliche Intelligenz Sinn KI-Forscher innen \n",
      " erreichen chatGPT   AGI Artificial General Intelligence \n",
      "\n",
      "\n",
      "TF-IDF scores:\n",
      "        agi  artificial  benutzeroberfläche   chatgpt      echt  eigentlich  \\\n",
      "0  0.133631    0.133631            0.133631  0.267261  0.133631    0.267261   \n",
      "\n",
      "      enorm  erreichen       etc  forscher  ...  situation  sprachmodell  \\\n",
      "0  0.133631   0.133631  0.133631  0.133631  ...   0.133631      0.133631   \n",
      "\n",
      "       text  verbirgen  vergleichbar  wahrheitsmaschine  weltgeist  \\\n",
      "0  0.267261   0.133631      0.133631           0.133631   0.133631   \n",
      "\n",
      "   wohlgeformt      wort    wählen  \n",
      "0     0.133631  0.133631  0.133631  \n",
      "\n",
      "[1 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.de.examples import sentences \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.cli import download\n",
    "import pandas as pd\n",
    "\n",
    "def load_model(model_name):\n",
    "    try:\n",
    "        nlp = spacy.load(model_name)\n",
    "    except OSError:\n",
    "        download(model_name)         # lädt das passende Paket ins aktuelle Python-Umfeld\n",
    "        nlp = spacy.load(model_name)\n",
    "    return nlp\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = load_model(\"de_core_news_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = text1 + text2 \n",
    "\n",
    "# Lemmatization using spaCy\n",
    "doc = nlp(text)\n",
    "lemmatized_text = \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(text)\n",
    "print(\"\\nLemmatized text:\")\n",
    "print(lemmatized_text)\n",
    "\n",
    "# TF-IDF calculation\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([lemmatized_text])\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "print(\"\\nTF-IDF scores:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9466cb",
   "metadata": {},
   "source": [
    "Das ist schon sehr beeindruckend, aber noch vergleichsweise naiv: Wäre es nicht schöner, wenn wir statt dessen eine KI fragen, welches die wichtigsten Wörter in einem Text sind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31060d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c69101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "model = \"mistral-medium-latest\"\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "def ask(prompt):\n",
    "    chat_response = client.chat.complete(\n",
    "        model= model,\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    return chat_response.choices[0].message.content   \n",
    "\n",
    "\n",
    "# Hier ergänzen: Das Modell soll selbst Keywords extrahieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823ebc3",
   "metadata": {},
   "source": [
    "## Audio verschriftlichen\n",
    "\n",
    "...und es wird noch cooler! Mit der richtigen Bibliothek kann man auch Audio in Text verwandeln: **Whisper** von OpenAI wurde ursprünglich dazu entwickelt, um (vor allem) Youtube-Videos zu transkribieren. Und setzt seitdem den Standard für saubere Transkription. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f03675c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faster_whisper in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: ctranslate2<5,>=4.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from faster_whisper) (4.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from faster_whisper) (1.0.1)\n",
      "Requirement already satisfied: tokenizers<1,>=0.13 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from faster_whisper) (0.22.1)\n",
      "Requirement already satisfied: onnxruntime<2,>=1.14 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from faster_whisper) (1.23.2)\n",
      "Requirement already satisfied: av>=11 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from faster_whisper) (16.0.1)\n",
      "Requirement already satisfied: tqdm in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from faster_whisper) (4.67.1)\n",
      "Requirement already satisfied: setuptools in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from ctranslate2<5,>=4.0->faster_whisper) (80.9.0)\n",
      "Requirement already satisfied: numpy in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from ctranslate2<5,>=4.0->faster_whisper) (2.3.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.3 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from ctranslate2<5,>=4.0->faster_whisper) (6.0.3)\n",
      "Requirement already satisfied: coloredlogs in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (25.9.23)\n",
      "Requirement already satisfied: packaging in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (25.0)\n",
      "Requirement already satisfied: protobuf in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (6.33.0)\n",
      "Requirement already satisfied: sympy in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from onnxruntime<2,>=1.14->faster_whisper) (1.14.0)\n",
      "Requirement already satisfied: filelock in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster_whisper) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster_whisper) (2025.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster_whisper) (0.28.1)\n",
      "Requirement already satisfied: shellingham in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster_whisper) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster_whisper) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster_whisper) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from huggingface-hub>=0.13->faster_whisper) (1.2.0)\n",
      "Requirement already satisfied: anyio in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.13->faster_whisper) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.13->faster_whisper) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.13->faster_whisper) (1.0.9)\n",
      "Requirement already satisfied: idna in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.13->faster_whisper) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.13->faster_whisper) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.13->faster_whisper) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from sympy->onnxruntime<2,>=1.14->faster_whisper) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in ./vfm-Programmieren/.conda/lib/python3.12/site-packages (from typer-slim->huggingface-hub>=0.13->faster_whisper) (8.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Erst die Bibliothek holen\n",
    "!pip install faster_whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb9a65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Der Fall Ein 59-Jähriger hört gerne laut Musik. Das ärgert seinen Nachbarn Herrn K. Nach 22 Uhr reicht es ihm und er dreht mehrfach die Sicherung im Haus raus. Der Musikliebhaber dreht sie mehrfach wieder rein und wird irgendwann so wütend, dass er sich ein Messer nimmt und bei Herrn K. kingelt. Doch der öffnet die Tür nicht komplett und der Musikliebhaber sticht durch den Türspalt auf ihn ein. Deshalb steht der Nachbar von Herrn K. im Mai 2025 vorm Schwurgericht in Frankfurt am Main. Der Vorwurf versuchter Totschlag.\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import os\n",
    "\n",
    "model = WhisperModel(\n",
    "    \"deepdml/faster-whisper-large-v3-turbo-ct2\",  # CT2 model id\n",
    "    device=\"cpu\",                 # or \"cuda\"\n",
    "    compute_type=\"int8\",          # good for CPU; try \"int8_float16\" on CUDA\n",
    ")\n",
    "\n",
    "path=\"./daten/demoaudio.mp3\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    print(f\"{path} gibt es leider nicht.\")\n",
    "    raise\n",
    "\n",
    "segments, info = model.transcribe(\n",
    "    path,\n",
    "    language=\"de\",                # force German\n",
    "    beam_size=5,\n",
    "    temperature=0.0,\n",
    "    vad_filter=True,              # optional: basic VAD\n",
    ")\n",
    "\n",
    "text = \"\".join(s.text for s in segments)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849d883",
   "metadata": {},
   "source": [
    "**Jetzt du**: Schreib eine Funktion, die Audios in Text umwandeln kann. Übergib der Funktion den Pfad zu einer Audio-Datei, die du in Text verwandeln möchtest. \n",
    "\n",
    "TIPP: Whisper kann nicht mit allen Dateitypen umgehen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b7fb2",
   "metadata": {},
   "source": [
    "## Bild beschreiben\n",
    "\n",
    "Moderne Sprachmodelle verstehen nicht nur Text, sondern sind **multimodal** - das heißt, man kann ihnen auch Bilddateien als Eingabe geben. \n",
    "\n",
    "Kannst du mit der Funktion hier einen Bildbeschreiber bauen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93438f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Generation function\n",
    "def generate_response(prompt ='', \n",
    "                      imageprompt = None,\n",
    "                      model='gpt-4o',\n",
    "                      client = None):\n",
    "    base64_image = imageprompt.split(',')[1] if imageprompt else None\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\":  f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                            }\n",
    "                        },\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=300,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der API-Anfrage: {e}\")\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
