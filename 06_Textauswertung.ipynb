{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daf71da",
   "metadata": {},
   "source": [
    "# 06 Texte auswerten mit dem Computer\n",
    "\n",
    "Ein wenig rechnen mit Wörtern: Welche Stichwörter beschreiben einen Text am besten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import re\n",
    "    \n",
    "def bag_of_words(text):\n",
    "    # Convert to lowercase and extract words\n",
    "    \n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    \n",
    "    # Count frequencies and return as dict sorted by frequency\n",
    "    word_counts = Counter(words)\n",
    "    return dict(sorted(word_counts.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "text1 = \"\"\"\n",
    "Was chatGPT (etc.) eigentlich ist: eine Benutzeroberfläche, unter der sich ein so \n",
    "genanntes “Generatives Sprachmodell” verbirgt, die eigentliche KI: eine Maschine, \n",
    "die wohlgeformte Texte produzieren kann. Das hat sie aus einer enormen Menge von \n",
    "menschengemachten Texten gelernt: Wie würden Menschen in einer vergleichbaren \n",
    "Situation wohl das nächste Wort wählen? Und dann wieder das nächste, und wieder \n",
    "das nächste.  \n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"\n",
    "Was sie nicht ist: Eine Wahrheitsmaschine, ein Weltgeist oder eine echte \n",
    "“Künstliche Intelligenz” im Sinne dessen, was KI-Forscher:innen erst noch \n",
    "erreichen wollen: chatGPT ist keine  “AGI” (“Artificial General Intelligence”). \n",
    "\"\"\"\n",
    "\n",
    "print(bag_of_words(text1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802fd38",
   "metadata": {},
   "source": [
    "**Jetzt du:** Lass dir ein Programm schreiben, das die Häufigkeit der einzelnen Wörter angibt: Für ```text1```, für ```text2``` - und für beide Texte zusammen. \n",
    "\n",
    "## Topic Modeling: Die richtigen Schlagworte extrahieren\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bag_of_words(text1))\n",
    "print(bag_of_words(text2))\n",
    "print(bag_of_words(text1 + text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662655e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tf_idf_keywords(text, threshold=4):\n",
    "    # Simple TF-IDF implementation\n",
    " \n",
    "    \n",
    "    # Tokenize and normalize\n",
    "    words = re.findall(r'\\w+', text.lower())\n",
    "    \n",
    "    # Calculate term frequency\n",
    "    tf = Counter(words)\n",
    "    \n",
    "    # Calculate document frequency\n",
    "    df = Counter()\n",
    "    for doc in words:\n",
    "        doc_words = set(re.findall(r'\\w+', doc.lower()))\n",
    "        for word in doc_words:\n",
    "            df[word] += 1\n",
    "    \n",
    "    # Calculate TF-IDF scores\n",
    "    tf_idf = {}\n",
    "    N = len(words)\n",
    "    \n",
    "    for word, frequency in tf.items():\n",
    "        if word in df:\n",
    "            idf = math.log(N / df[word])\n",
    "            val = frequency * idf\n",
    "            if val >= threshold:\n",
    "                tf_idf[word] = val\n",
    "    \n",
    "    # Return sorted keywords by weight\n",
    "    return dict(sorted(tf_idf.items(), key=lambda x: x[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de2aea",
   "metadata": {},
   "source": [
    "**Jetzt du**: Wende die tf_idf Funktion auf text1 und text2 an - und vergleiche mit dem Bag of words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bag_of_words(text1 + text2))\n",
    "print(tf_idf_keywords(text1 + text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1203d009",
   "metadata": {},
   "source": [
    "Okay... aber zu viel Müll: Wir müssen: \n",
    "- die **Stoppwörter** rausnehmen (ein, die, und...)\n",
    "- die Wortstämme (Lemmata) extrahieren\n",
    "\n",
    "Das machen wir mit einer Spezial-Bibliothek (die auch schon ein wenig KI benutzt): Spacy. \n",
    "\n",
    "Außerdem benutzen wir die Tabellen-Bibliothek pandas - und wir geben ihr einen anderen Namen. Details sind nicht so wichtig; einfach schauen: ähnliche Code-Schnipsel sieht man sehr oft!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install scikit.learn\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.de.examples import sentences \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.cli import download\n",
    "import pandas as pd\n",
    "\n",
    "def load_model(model_name):\n",
    "    try:\n",
    "        nlp = spacy.load(model_name)\n",
    "    except OSError:\n",
    "        download(model_name)         # lädt das passende Paket ins aktuelle Python-Umfeld\n",
    "        nlp = spacy.load(model_name)\n",
    "    return nlp\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = load_model(\"de_core_news_sm\")\n",
    "\n",
    "# Sample text\n",
    "text = text1 + text2 \n",
    "\n",
    "# Lemmatization using spaCy\n",
    "doc = nlp(text)\n",
    "lemmatized_text = \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(text)\n",
    "print(\"\\nLemmatized text:\")\n",
    "print(lemmatized_text)\n",
    "\n",
    "# TF-IDF calculation\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform([lemmatized_text])\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "print(\"\\nTF-IDF scores:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9466cb",
   "metadata": {},
   "source": [
    "Das ist schon sehr beeindruckend, aber noch vergleichsweise naiv: Wäre es nicht schöner, wenn wir statt dessen eine KI fragen, welches die wichtigsten Wörter in einem Text sind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31060d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c69101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "\n",
    "api_key = \"AVtuDWTw4B0dS70w3nssuwFUnkhQuU0c\"\n",
    "model = \"mistral-medium-latest\"\n",
    "\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "def ask(prompt):\n",
    "    chat_response = client.chat.complete(\n",
    "        model= model,\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "    return chat_response.choices[0].message.content   \n",
    "\n",
    "\n",
    "# Hier ergänzen: Das Modell soll selbst Keywords extrahieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823ebc3",
   "metadata": {},
   "source": [
    "## Audio verschriftlichen\n",
    "\n",
    "...und es wird noch cooler! Mit der richtigen Bibliothek kann man auch Audio in Text verwandeln: **Whisper** von OpenAI wurde ursprünglich dazu entwickelt, um (vor allem) Youtube-Videos zu transkribieren. Und setzt seitdem den Standard für saubere Transkription. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03675c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erst die Bibliothek holen\n",
    "!pip install faster_whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "import os\n",
    "\n",
    "model = WhisperModel(\n",
    "    \"deepdml/faster-whisper-large-v3-turbo-ct2\",  # CT2 model id\n",
    "    device=\"cpu\",                 # or \"cuda\"\n",
    "    compute_type=\"int8\",          # good for CPU; try \"int8_float16\" on CUDA\n",
    ")\n",
    "\n",
    "path=\"./daten/demoaudio.mp3\"\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    print(f\"{path} gibt es leider nicht.\")\n",
    "    raise\n",
    "\n",
    "segments, info = model.transcribe(\n",
    "    path,\n",
    "    language=\"de\",                # force German\n",
    "    beam_size=5,\n",
    "    temperature=0.0,\n",
    "    vad_filter=True,              # optional: basic VAD\n",
    ")\n",
    "\n",
    "text = \"\".join(s.text for s in segments)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849d883",
   "metadata": {},
   "source": [
    "**Jetzt du**: Schreib eine Funktion, die Audios in Text umwandeln kann. Übergib der Funktion den Pfad zu einer Audio-Datei, die du in Text verwandeln möchtest. \n",
    "\n",
    "TIPP: Whisper kann nicht mit allen Dateitypen umgehen!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
